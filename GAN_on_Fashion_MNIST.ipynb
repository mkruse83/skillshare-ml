{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc816546-fde9-47b4-8ccd-e2482c5f83de",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Generative Adversarial Networks #\n",
    "\n",
    "First make sure we have a GPU available, or this will take a really long time to train. If you don't, refer to https://www.tensorflow.org/install/gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1589d5f2-bb54-4b94-8025-29b1a4b54094",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gtnTWSftUUCg",
    "outputId": "8bf57941-2e21-434b-ed76-3ad412b751a3"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# maintain consistent performance\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "# confirm GPU is available\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a2ba986-ee58-47a6-be36-4a63179afb2e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "As before, we'll load up the Fashion MNIST dataset, merge it all together since we're not doing train/test, and normalize the data as we did with VAE's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6adaf69-47e9-4b2c-a256-b6e22dfa1aa9",
     "showTitle": false,
     "title": ""
    },
    "id": "755TV2iFUa6t"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "# load the Fashion MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5936d920-c1c1-43dc-a13a-3d05a6489ef4",
     "showTitle": false,
     "title": ""
    },
    "id": "J9tBjaE7Uglq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# merge the training and testing sets\n",
    "dataset = np.concatenate([x_train, x_test], axis=0)\n",
    "# normalize the images from [0,255] to [0,1]\n",
    "dataset = np.expand_dims(dataset, -1).astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e0f9f171-45a4-48ba-99f6-62f97c42f3a4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Now we will reshape the data to the dimensions needed by the CNN layers, shuffle, and batch it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38b6b8de-2f86-44b3-ae3c-a9663ae21ad1",
     "showTitle": false,
     "title": ""
    },
    "id": "e9TxZEsmggAA"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "# convolution layers work 3 channels\n",
    "dataset = np.reshape(dataset, (-1, 28, 28, 1))\n",
    "# create a tensorflow dataset object\n",
    "dataset = tf.data.Dataset.from_tensor_slices(dataset)\n",
    "# set the batch size otherwise it reads one image at a time\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "deb5c621-e431-4e2e-8719-c4143400da68",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Now let's set up the model for our generator. Note the NOISE_DIM hyperparameter. From there we have three Conv2DTranspose layers to work our way to a final generated image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7830733a-2262-4512-8094-a4cbbe1775a1",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lME6mHDUUm5a",
    "outputId": "c274b10e-6ab8-483a-9d97-523f177570c0"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# the generator's input is a noise vector\n",
    "# hyper-parameter that also requires fine-tuning\n",
    "NOISE_DIM = 150\n",
    "\n",
    "# design a generator model with upsampling layers\n",
    "# in GANs practices, usually the generator has leaky relu activation while the discriminator has relu\n",
    "generator = keras.models.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(NOISE_DIM,)),\n",
    "  layers.Dense(7*7*256),\n",
    "  layers.Reshape(target_shape=(7, 7, 256)),\n",
    "  layers.Conv2DTranspose(256, 3, activation=\"LeakyReLU\", strides=2, padding=\"same\"),\n",
    "  layers.Conv2DTranspose(128, 3, activation=\"LeakyReLU\", strides=2, padding=\"same\"),\n",
    "  layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")\n",
    "])\n",
    "\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1cfc2cf1-424a-4eb7-b612-a5fb8e2c859c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Next we'll make our discriminator model, using two Conv2D layers to downsample before going into a 64-neuron dense layer and a dropout to avoid overfitting. Its output is binary, as its job is to classify images as \"real\" or \"fake\"... until it can no longer tell the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12a9cfbf-604c-4292-a24a-d27a9a83a031",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "vWzojd59XLlD",
    "outputId": "a2da7800-0963-42ca-90f1-64af3e080669"
   },
   "outputs": [],
   "source": [
    "# design a discriminator with downsampling layers\n",
    "discriminator = keras.models.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28, 28, 1)),\n",
    "  layers.Conv2D(256, 3, activation=\"relu\", strides=2, padding=\"same\"),\n",
    "  layers.Conv2D(128, 3, activation=\"relu\", strides=2, padding=\"same\"),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(64, activation=\"relu\"),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88fb056e-6806-4c91-b91a-06d7ce5794f9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Set up our optimizers, loss function, and accuracy metrics. Whee, more hyperparameters - getting the learning rates just right on both the generator and discriminator is the key. Otherwise it won't be stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c4f99ddc-b8e3-4112-b214-e76f33be9b4e",
     "showTitle": false,
     "title": ""
    },
    "id": "0LZk4emzePCm"
   },
   "outputs": [],
   "source": [
    "# set different learning rates for the generator and the discriminator\n",
    "# we want to maintain the game balance until we arrive at the nash-equilibria\n",
    "# if the discriminator gets very strong or very weak the adversarial game fails\n",
    "# higher learning rates impact the stability of the adversarial game severely\n",
    "optimizerG = keras.optimizers.Adam(learning_rate=0.00001, beta_1=0.5)\n",
    "optimizerD = keras.optimizers.Adam(learning_rate=0.00003, beta_1=0.5)\n",
    "\n",
    "# binary classifier (real or fake)\n",
    "lossFn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "# accuracy metric\n",
    "gAccMetric = tf.keras.metrics.BinaryAccuracy()\n",
    "dAccMetric = tf.keras.metrics.BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30d1dfbb-7ef4-47b1-a0d5-9a0b0cbaaa5d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "OK, let's tie them together. We initially feed our generator gaussian noise. Its \"fake\" outputs are concatenated to \"real\" data fed into the discriminator. The discriminator does its best to identify real vs. fake labels. Here we define the training function for the discriminator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "69b8bd0d-1bcd-4839-b9a0-dcc62bd2d598",
     "showTitle": false,
     "title": ""
    },
    "id": "SZW92KQcVPir"
   },
   "outputs": [],
   "source": [
    "# observe the annotation allows for efficient native tensoflow compiling\n",
    "@tf.function\n",
    "def trainDStep(data):\n",
    "  # the batch is (32,28,28,1), so extract 32 value\n",
    "  batchSize = tf.shape(data)[0]\n",
    "  # create a noise vector as generator input sampled from Gaussian Random Normal\n",
    "  # As an exercise try sampling from a uniform distribution and observe the difference\n",
    "  noise = tf.random.normal(shape=(batchSize, NOISE_DIM))\n",
    "\n",
    "  # concatenate the real and fake labels\n",
    "  y_true = tf.concat(\n",
    "    [\n",
    "      # the original data is real, labeled with 1\n",
    "      tf.ones(batchSize, 1),\n",
    "      # the forged data is fake, labeled with 0\n",
    "      tf.zeros(batchSize, 1)\n",
    "    ],\n",
    "    axis=0\n",
    "  )\n",
    "\n",
    "  # record the calculated gradients\n",
    "  with tf.GradientTape() as tape:\n",
    "    # generate forged samples\n",
    "    fake = generator(noise)\n",
    "    # concatenate real data and forged data\n",
    "    x = tf.concat([data, fake], axis=0)\n",
    "    # see if the discriminator detects them\n",
    "    y_pred = discriminator(x)\n",
    "    # calculate the loss\n",
    "    discriminatorLoss = lossFn(y_true, y_pred)\n",
    "\n",
    "  # apply the backward path and update weights\n",
    "  grads = tape.gradient(discriminatorLoss, discriminator.trainable_weights)\n",
    "  optimizerD.apply_gradients(zip(grads, discriminator.trainable_weights))\n",
    "\n",
    "  # report accuracy\n",
    "  dAccMetric.update_state(y_true, y_pred)\n",
    "\n",
    "  # return the loss for visualization\n",
    "  return {\n",
    "      \"discriminator_loss\": discriminatorLoss,\n",
    "      \"discriminator_accuracy\": dAccMetric.result()\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6411c994-56db-4d96-a321-dc975e81154e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "And now, the training function for the generator. Remember the generator is trying not to get caught, and so it wants to be classified as real. Its loss function is based on how often the discriminator classifies its fake samples as real. This is in tension with the discriminator, which is trying to find fakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e72ff936-ca40-49ac-8cd4-da63ba051e94",
     "showTitle": false,
     "title": ""
    },
    "id": "JsVM-ljvhBVA"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def trainGStep(data):\n",
    "  batchSize = tf.shape(data)[0]\n",
    "  noise = tf.random.normal(shape=(batchSize, NOISE_DIM))\n",
    "  # when training the generator, we want it to maximize the probability that its\n",
    "  # output is classified as real, remember the min-max game\n",
    "  y_true = tf.ones(batchSize, 1)\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    y_pred = discriminator(generator(noise))\n",
    "    generatorLoss = lossFn(y_true, y_pred)\n",
    "\n",
    "  grads = tape.gradient(generatorLoss, generator.trainable_weights)\n",
    "  optimizerG.apply_gradients(zip(grads, generator.trainable_weights))\n",
    "\n",
    "  gAccMetric.update_state(y_true, y_pred)\n",
    "\n",
    "  return {\n",
    "      \"generator_loss\": generatorLoss,\n",
    "      \"generator_accuracy\": gAccMetric.result()\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3a87ee5-2255-4881-a328-cc42d74b11e3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's set up a handy function to visualize generated images as we train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48925fb9-6f81-4476-a519-2ef6c8b8f098",
     "showTitle": false,
     "title": ""
    },
    "id": "BhRFUbH5SYSE"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def plotImages(model):\n",
    "    images = model(np.random.normal(size=(81, NOISE_DIM)))\n",
    "\n",
    "    plt.figure(figsize=(9, 9))\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(9,9,i+1)\n",
    "        plt.imshow(np.squeeze(image, -1), cmap=\"Greys_r\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db304920-eadd-44e0-aa58-991c58ec9e49",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Now it's showtime. Since the adversarial game is a delicate balance, we want to observe the results as training progresses. It may converge and then diverge again; it is very touchy stuff. Here we just go through each batch, train the discriminator, and train the generator each epoch. Every other epoch we'll peek at some generated images to see how they are looking, as the generator learns probability distributions to represent realistic images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d74728c4-393b-46a9-9727-818261435e89",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 656
    },
    "id": "55kFj5xOdQBI",
    "outputId": "72bc9ce2-69a7-4f54-d2d0-7121b58a5a6d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# we don't use the model.fit method any more since the original GANs paper trained\n",
    "# the discriminator for 5 steps and then the generator for 1 step\n",
    "# the value 5 is subject to fine-tuning depending on the model design and the dataset\n",
    "# in this example, training both for 1 step\n",
    "# note: the adversarial game may diverge after it has converged\n",
    "# that's why it is customary to visualize the generated images every few epochs\n",
    "# some even put the images together into a video\n",
    "for epoch in range(30):\n",
    "\n",
    "  # accumulate the loss to calculate the average at the end of the epoch\n",
    "  dLossSum = 0\n",
    "  gLossSum = 0\n",
    "  dAccSum = 0\n",
    "  gAccSum = 0\n",
    "  cnt = 0\n",
    "\n",
    "  # loop the dataset one batch at a time\n",
    "  for batch in dataset:\n",
    "\n",
    "    # train the discriminator\n",
    "    # remember you could repeat these 2 lines of code for K times\n",
    "    dLoss = trainDStep(batch)\n",
    "    dLossSum += dLoss['discriminator_loss']\n",
    "    dAccSum += dLoss['discriminator_accuracy']\n",
    "\n",
    "    # train the generator\n",
    "    gLoss = trainGStep(batch)\n",
    "    gLossSum += gLoss['generator_loss']\n",
    "    gAccSum += gLoss['generator_accuracy']\n",
    "\n",
    "    # increment the counter\n",
    "    cnt += 1\n",
    "\n",
    "  # log the performance\n",
    "  print(\"E:{}, Loss G:{:0.4f}, Loss D:{:0.4f}, Acc G:%{:0.2f}, Acc D:%{:0.2f}\".format(\n",
    "      epoch,\n",
    "      gLossSum/cnt,\n",
    "      dLossSum/cnt,\n",
    "      100 * gAccSum/cnt,\n",
    "      100 * dAccSum/cnt\n",
    "  ))\n",
    "    \n",
    "  if epoch % 2 == 0:\n",
    "    plotImages(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8fccc78-3bb3-475a-810d-20e56cc8ef61",
     "showTitle": false,
     "title": ""
    },
    "id": "guu-x29SfJpY"
   },
   "outputs": [],
   "source": [
    "# generate some images with the trained model\n",
    "# observe how fast it is compared to rendering an image with computer graphics algorithms\n",
    "# that's why GANs can revolutize the video games industry by generating realistic scenes\n",
    "# observe how the generated samples seem to belong to the same or similar class; this is the\n",
    "# \"mode collapse problem\" of GAN's.\n",
    "images = generator(np.random.normal(size=(81, NOISE_DIM)))\n",
    "\n",
    "# plot the generated samples\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(9, 9))\n",
    "\n",
    "for i, image in enumerate(images):\n",
    "    plt.subplot(9,9,i+1)\n",
    "    plt.imshow(np.squeeze(image, -1), cmap=\"Greys_r\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60dbfdd4-ed2c-4b87-94ae-ea63209860da",
     "showTitle": false,
     "title": ""
    },
    "id": "lXTglrSDEJnM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "GAN_on_Fashion_MNIST",
   "widgets": {}
  },
  "colab": {
   "collapsed_sections": [],
   "name": "GAN_on_Fashion_MNIST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
